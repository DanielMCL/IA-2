{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUBRwgEu3yu1"
   },
   "source": [
    "# Práctica 2: Procesamiento del Lenguaje Natural\n",
    "\n",
    "__Fecha de entrega: 8 de mayo de 2023__\n",
    "\n",
    "El objetivo de esta práctica es aplicar los conceptos teóricos vistos en clase en el módulo de PLN. La práctica consta de 2 notebooks que se entregarán simultáneamente en la tarea de entrega habilitada en el Campus  Virtual.\n",
    "\n",
    "Lo más importante en esta práctica no es el código Python, sino el análisis de los datos y modelos que construyas y las explicaciones razonadas de cada una de las decisiones que tomes. __No se valorarán trozos de código o gráficas sin ningún tipo de contexto o explicación__.\n",
    "\n",
    "Finalmente, recuerda establecer el parámetro `random_state` en todas las funciones que tomen decisiones aleatorias para que los resultados sean reproducibles (los resultados no varíen entre ejecuciones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "V3YxCTUW3yu9"
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pn_YQLVL3yvA"
   },
   "source": [
    "# Apartado 1: Análisis de sentimientos con word embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de-i8w0s3yvC"
   },
   "source": [
    "__Número de grupo: XX__\n",
    "\n",
    "__Nombres de los estudiantes: Gonzalo Garcia Fernández y Daniel María Carreño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeVD_g2D3yvC"
   },
   "source": [
    "## 1) Carga del conjunto de datos\n",
    "\n",
    "El fichero `IMBD_Dataset.csv` contiene opiniones de películas clasificadas en 2 categorías diferentes (positiva/negativa).\n",
    "\n",
    "Este set de datos se creó utilizando el \"IMDB Dataset of 50K Movie Reviews\", el cual contiene 50,000 reseñas de películas con un sentimiento positivo o negativo adjunto a ellas.\n",
    "\n",
    "Muestra un ejemplo de cada clase.\n",
    "\n",
    "Haz un estudio del conjunto de datos. ¿qué palabras aparecen más veces?, ¿tendría sentido normalizar de alguna manera el corpus?\n",
    "\n",
    "Crea una partición de los datos dejando el 80% para entrenamiento y el 20% restante para test usando la función `train_test_split` de sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YyPy4BDfzGQ",
    "outputId": "24fb5c07-4baf-4df2-be20-c09af6b89f80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# acceso a google drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0csu2B8N3yvE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "YAAhipiYm5eh",
    "outputId": "e0cc0f8f-359d-4dd0-b439-0474feecd847"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6cf4834b-2ebb-4c92-a612-35cbc41cc536\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cf4834b-2ebb-4c92-a612-35cbc41cc536')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6cf4834b-2ebb-4c92-a612-35cbc41cc536 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6cf4834b-2ebb-4c92-a612-35cbc41cc536');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imbd_file = '/content/drive/MyDrive/IMDB_Dataset.csv'\n",
    "\n",
    "df=pd.read_csv(imbd_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydN4zilcaXhP",
    "outputId": "9f67bafe-0bae-459b-a924-7ecf828a279a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPPAH1d1aeTn"
   },
   "source": [
    "Vemos con el output del anterior que nuestra base de datos esta perfectamente equilibrada y tiene 50000 ejemplos(250000 negativos y 25000 positivos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "npWL7CqaS1Kc",
    "outputId": "43c6be89-b67c-4d2f-b619-7a0d2cc94a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo positivo:\n",
      "0    One of the other reviewers has mentioned that ...\n",
      "Name: review, dtype: object\n",
      "Ejemplo negativo:\n",
      "3    Basically there's a family where a little boy ...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "corpus =np.array(df['review'])\n",
    "df2 = df[df['sentiment'] == 'positive']\n",
    "print('Ejemplo positivo:')\n",
    "print(df2.head(1)['review'])\n",
    "\n",
    "df3 = df[df['sentiment'] == 'negative']\n",
    "print('Ejemplo negativo:')\n",
    "print(df3.head(1)['review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EcqNWMJsWd9D",
    "outputId": "95b77a40-146d-4e23-c56a-42d6615c898f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  7, 16],\n",
       "       [ 7,  5, 16],\n",
       "       [ 4,  4,  8],\n",
       "       ...,\n",
       "       [ 6, 11, 21],\n",
       "       [ 8,  7, 13],\n",
       "       [ 2,  2, 12]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus =np.array(df['review'])\n",
    "cv = CountVectorizer(max_features = 3)\n",
    "cv_matrix = cv.fit_transform(corpus)\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "M77Ey3Etgdmi",
    "outputId": "1a6e7b15-be45-42b0-f228-918f319d3027"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d35d5fc6-2480-4a0d-bf42-a940afa72f94\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d35d5fc6-2480-4a0d-bf42-a940afa72f94')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d35d5fc6-2480-4a0d-bf42-a940afa72f94 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d35d5fc6-2480-4a0d-bf42-a940afa72f94');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       and  of  the\n",
       "0        6   7   16\n",
       "1        7   5   16\n",
       "2        4   4    8\n",
       "3        4   2    6\n",
       "4        5   6   20\n",
       "...    ...  ..  ...\n",
       "49995    7   2    5\n",
       "49996    2   4    9\n",
       "49997    6  11   21\n",
       "49998    8   7   13\n",
       "49999    2   2   12\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all unique words in the corpus\n",
    "vocab = cv.get_feature_names_out()\n",
    "# show document feature vectors\n",
    "pd.DataFrame(cv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zixUcIHaiLdD"
   },
   "source": [
    "Como podemos ver las palabras más tipicas del texto sin normalizar son las más utilizadas en inglés lo que no nos da ninguna información. Por lo tanto, normalizaremos el texto para poder ver realmente cuales son las palabras más utilizadas relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vsly08jaYRXM",
    "outputId": "37c38bcd-0f32-41d1-96da-122388646d2f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "wpt = nltk.WordPunctTokenizer()\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = re.sub('br','',doc)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cCZNOGJsalUT"
   },
   "outputs": [],
   "source": [
    "norm_corpus = normalize_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0kRTHqDNitWL",
    "outputId": "7818bd30-f74a-4630-bfb1-7bcfdfd1d336"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 4],\n",
       "       [0, 7, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 3)\n",
    "cv_matrix = cv.fit_transform(norm_corpus)\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Yyi7maAwivOl",
    "outputId": "cf463a3c-1f57-4909-d5a0-07547cee9194"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7a9d7ca5-73d7-49f6-86e3-e208dca64c78\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>movie</th>\n",
       "      <th>one</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a9d7ca5-73d7-49f6-86e3-e208dca64c78')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7a9d7ca5-73d7-49f6-86e3-e208dca64c78 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7a9d7ca5-73d7-49f6-86e3-e208dca64c78');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       film  movie  one\n",
       "0         0      0    1\n",
       "1         0      0    1\n",
       "2         0      0    1\n",
       "3         2      3    0\n",
       "4         2      1    6\n",
       "...     ...    ...  ...\n",
       "49995     0      5    1\n",
       "49996     0      0    0\n",
       "49997     0      0    0\n",
       "49998     0      0    4\n",
       "49999     0      7    1\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all unique words in the corpus\n",
    "vocab = cv.get_feature_names_out()\n",
    "# show document feature vectors\n",
    "pd.DataFrame(cv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ODgcO7ljdtG"
   },
   "source": [
    "Ahora ya podemos ver que nuestro dataset sera referente a peliculas porque las palabras más frecuentes son \"movie\" y \"film\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-QYTIVa-GiL",
    "outputId": "2266a388-90d3-4ab5-806d-d45f67c7de2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    20000\n",
       "positive    20000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "review_train,review_test,sentiment_train,sentiment_test = train_test_split(df['review'],df['sentiment'],test_size= 0.20,stratify=df['sentiment'],random_state = RANDOM_STATE)#usamos la funcion train_test_split de sklear con un 20% de ejemplos para el test.\n",
    "sentiment_train.value_counts()#contamos el numero de valoraciones positivas y negativas que hay en el train y vemos que son iguales\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BV90ccByaL7_",
    "outputId": "9d8e1e24-dfa7-435c-9379-ca8cf58fdead"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    5000\n",
       "positive    5000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_test.value_counts() #contamos el numero de valoraciones positivas y negativas que hay en el test y vemos que son iguales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zuz_eSElaxg_"
   },
   "source": [
    "Despues de realizar esto vemos que de los 50000 ejemplos nos ha cogido 40000 para el entrenamiento y 10000 para el test. Como podemos apreciar la distribucion de las clases está muy equilibrada gracias al parámetro añadido startify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4rXv3xX3yvG"
   },
   "source": [
    "## 2) Estudio del efecto de distintas configuraciones de word embeddings para resolver la tara\n",
    "\n",
    "Usa distintas configuraciones de word embeddigns y discute los resultados obtenidos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lggskUJIoS60"
   },
   "source": [
    "Vamos a entrenar el clasificador con 3 configuraciones de word embeddings distintas.\n",
    "\n",
    "La primera de ella será sin entrenamiento previo, mientras que las otras dos harán uso de los embeddings pre-entrenados de 'glove.6B.50d.txt'. Una de ellas \"congelará\" lo ya pre-aprendido mientras que la otra podrá modificar esas capas.\n",
    "\n",
    "Utilizamos la librería keras tal y como en el tutorial. Para ello necesitamos que la columna sentiments tenga un valor númerico. Dado que ahora mismo dicha columna vale 'positive' o 'negative', la modificamos por la columna sentiments_num y le asignamos 1 o 0 segun el valor de sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "bsP4CebKYoGf"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(norm_corpus, df['sentiment'])),columns=['review', 'sentiment'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BJm3JTSbT8mC"
   },
   "outputs": [],
   "source": [
    "df['sentiment_num'] = df['sentiment']\n",
    "for i in range(0, df['sentiment'].size):\n",
    "  if (df['sentiment'][i] == 'positive'): df['sentiment_num'][i] = (1);\n",
    "  else: df['sentiment_num'][i] = 0;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4e4vdapUrTpk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "aWmJLWY2YaNI",
    "outputId": "f1eff2a8-21e1-4a05-923c-5006d46764c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6e23ccc2-8047-402b-8428-5ebcdc9778dc\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching oz episode yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e23ccc2-8047-402b-8428-5ebcdc9778dc')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6e23ccc2-8047-402b-8428-5ebcdc9778dc button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6e23ccc2-8047-402b-8428-5ebcdc9778dc');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              review sentiment_num\n",
       "0  one reviewers mentioned watching oz episode yo...             1\n",
       "1  wonderful little production filming technique ...             1\n",
       "2  thought wonderful way spend time hot summer we...             1\n",
       "3  basically theres family little boy jake thinks...             0\n",
       "4  petter matteis love time money visually stunni...             1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.loc[:, ['review', 'sentiment_num']]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvGIme7hapyT",
    "outputId": "7fa1fc26-96f1-4fbc-a38e-693210a08770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 162162 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "max_words = 1500\n",
    "max_comment_length = 20\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(df2.review)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df2.review)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "max_words = len(word_index)\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=max_comment_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ix5hqF0ZZMja"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "d=df2.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, df2.sentiment_num, test_size=0.20, random_state=RANDOM_STATE, stratify = df2.sentiment_num)\n",
    "\n",
    "embedding_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wObqwslpw2le"
   },
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train).astype('float32')\n",
    "x_test = np.asarray(x_test).astype('float32')\n",
    "y_train = np.asarray(y_train).astype('float32')\n",
    "y_test = np.asarray(y_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6WLFEg9B6Uu9",
    "outputId": "820ba988-c0ba-4c01-83a7-d647fac5414d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 20, 50)            8108100   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,109,101\n",
      "Trainable params: 8,109,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 32s 20ms/step - loss: 0.4894 - accuracy: 0.7645 - val_loss: 0.4259 - val_accuracy: 0.8015\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3942 - accuracy: 0.8198 - val_loss: 0.4288 - val_accuracy: 0.7991\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.3442 - accuracy: 0.8483 - val_loss: 0.4498 - val_accuracy: 0.7880\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2885 - accuracy: 0.8834 - val_loss: 0.4917 - val_accuracy: 0.7787\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.2395 - accuracy: 0.9099 - val_loss: 0.5429 - val_accuracy: 0.7675\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1977 - accuracy: 0.9297 - val_loss: 0.6054 - val_accuracy: 0.7612\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1633 - accuracy: 0.9468 - val_loss: 0.6791 - val_accuracy: 0.7566\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1346 - accuracy: 0.9602 - val_loss: 0.7619 - val_accuracy: 0.7514\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1090 - accuracy: 0.9717 - val_loss: 0.8524 - val_accuracy: 0.7506\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0880 - accuracy: 0.9804 - val_loss: 0.9489 - val_accuracy: 0.7427\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0696 - accuracy: 0.9865 - val_loss: 1.0522 - val_accuracy: 0.7430\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0545 - accuracy: 0.9918 - val_loss: 1.1642 - val_accuracy: 0.7385\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0420 - accuracy: 0.9949 - val_loss: 1.2830 - val_accuracy: 0.7336\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0323 - accuracy: 0.9972 - val_loss: 1.3945 - val_accuracy: 0.7351\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0246 - accuracy: 0.9984 - val_loss: 1.5120 - val_accuracy: 0.7318\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0185 - accuracy: 0.9993 - val_loss: 1.6311 - val_accuracy: 0.7340\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0142 - accuracy: 0.9995 - val_loss: 1.7502 - val_accuracy: 0.7303\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0107 - accuracy: 0.9999 - val_loss: 1.8707 - val_accuracy: 0.7297\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0082 - accuracy: 0.9999 - val_loss: 1.9921 - val_accuracy: 0.7296\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1147 - val_accuracy: 0.7298\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.1147 - accuracy: 0.7298\n",
      "Accuracy: 72.98%\n"
     ]
    }
   ],
   "source": [
    "# MODELO 1. SIN EMBEDDINGS PRE-ENTRENADOS \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "\n",
    "model1 = Sequential()\n",
    "# We specify the maximum input length to our Embedding layer\n",
    "# so we can later flatten the embedded inputs\n",
    "\n",
    "\n",
    "model1.add(Embedding(max_words, embedding_dim, input_length=max_comment_length))\n",
    "# After the Embedding layer, our activations have shape `(max_words, max_comment_length, embedding_dim)`.\n",
    "\n",
    "# We flatten the 3D tensor of embeddings into a 2D tensor of shape `(max_words, max_comment_length * embedding_dim)`\n",
    "\n",
    "model1.add(Flatten())\n",
    "\n",
    "# We add the classifier on top\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model1.summary()\n",
    "\n",
    "history = model1.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "score1 = model1.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (score1[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lVwaG1btdC2G",
    "outputId": "7cf80268-3f41-483c-fc73-17929181b296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "glove_dir = '/content/drive/MyDrive/'\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.50d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Ge69VCUbvsNP"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < max_words:\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bm-hHZ12yJbg",
    "outputId": "7d08c9f0-cb8d-4b96-f483-c1190e6a4e90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 20, 50)            8108100   \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,109,101\n",
      "Trainable params: 8,109,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MODELO 2. EMBEDDINGS PRE-ENTRENADOS CONGELADOS\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(max_words, embedding_dim, input_length=max_comment_length))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "uyUlbX8ryTFQ"
   },
   "outputs": [],
   "source": [
    "model2.layers[0].set_weights([embedding_matrix])\n",
    "model2.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KKStEYAlyXa6",
    "outputId": "b7ce0ba1-8f79-418d-89f4-c4745cc2537b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6106 - accuracy: 0.6625 - val_loss: 0.5759 - val_accuracy: 0.6979\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5708 - accuracy: 0.7030 - val_loss: 0.5803 - val_accuracy: 0.6877\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5673 - accuracy: 0.7081 - val_loss: 0.5870 - val_accuracy: 0.6870\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5653 - accuracy: 0.7076 - val_loss: 0.5719 - val_accuracy: 0.7007\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5646 - accuracy: 0.7074 - val_loss: 0.5772 - val_accuracy: 0.6930\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 0.5649 - accuracy: 0.7084 - val_loss: 0.5726 - val_accuracy: 0.6961\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5649 - accuracy: 0.7090 - val_loss: 0.5892 - val_accuracy: 0.6911\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5651 - accuracy: 0.7087 - val_loss: 0.5715 - val_accuracy: 0.7001\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5644 - accuracy: 0.7096 - val_loss: 0.5738 - val_accuracy: 0.6994\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 0.5641 - accuracy: 0.7085 - val_loss: 0.5797 - val_accuracy: 0.6924\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5652 - accuracy: 0.7092 - val_loss: 0.5849 - val_accuracy: 0.6955\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5640 - accuracy: 0.7104 - val_loss: 0.5794 - val_accuracy: 0.6930\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5646 - accuracy: 0.7075 - val_loss: 0.5732 - val_accuracy: 0.7006\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5637 - accuracy: 0.7096 - val_loss: 0.5719 - val_accuracy: 0.7025\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5639 - accuracy: 0.7075 - val_loss: 0.5871 - val_accuracy: 0.6944\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5641 - accuracy: 0.7086 - val_loss: 0.5730 - val_accuracy: 0.6982\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5634 - accuracy: 0.7107 - val_loss: 0.5748 - val_accuracy: 0.6991\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5634 - accuracy: 0.7105 - val_loss: 0.5744 - val_accuracy: 0.6973\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5637 - accuracy: 0.7082 - val_loss: 0.5724 - val_accuracy: 0.6985\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5635 - accuracy: 0.7081 - val_loss: 0.5750 - val_accuracy: 0.7010\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5750 - accuracy: 0.7010\n"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model2.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "score2 = model2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taB6Upj2ymrG",
    "outputId": "86a43a26-b8ed-471d-a8ad-6c9d6fab502f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 20, 50)            8108100   \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,109,101\n",
      "Trainable params: 8,109,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 20s 15ms/step - loss: 0.5441 - accuracy: 0.7181 - val_loss: 0.4581 - val_accuracy: 0.7801\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.4247 - accuracy: 0.8027 - val_loss: 0.4384 - val_accuracy: 0.7957\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3929 - accuracy: 0.8195 - val_loss: 0.4440 - val_accuracy: 0.7933\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.3683 - accuracy: 0.8338 - val_loss: 0.4522 - val_accuracy: 0.7892\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3420 - accuracy: 0.8503 - val_loss: 0.4697 - val_accuracy: 0.7810\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.3149 - accuracy: 0.8643 - val_loss: 0.4883 - val_accuracy: 0.7779\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2888 - accuracy: 0.8796 - val_loss: 0.5184 - val_accuracy: 0.7682\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2630 - accuracy: 0.8920 - val_loss: 0.5484 - val_accuracy: 0.7654\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2391 - accuracy: 0.9054 - val_loss: 0.5853 - val_accuracy: 0.7622\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2163 - accuracy: 0.9178 - val_loss: 0.6244 - val_accuracy: 0.7574\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1956 - accuracy: 0.9273 - val_loss: 0.6694 - val_accuracy: 0.7517\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1755 - accuracy: 0.9376 - val_loss: 0.7133 - val_accuracy: 0.7499\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1570 - accuracy: 0.9465 - val_loss: 0.7691 - val_accuracy: 0.7461\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1391 - accuracy: 0.9564 - val_loss: 0.8278 - val_accuracy: 0.7441\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1228 - accuracy: 0.9649 - val_loss: 0.8837 - val_accuracy: 0.7417\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1073 - accuracy: 0.9714 - val_loss: 0.9502 - val_accuracy: 0.7376\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0926 - accuracy: 0.9776 - val_loss: 1.0184 - val_accuracy: 0.7363\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0792 - accuracy: 0.9835 - val_loss: 1.0921 - val_accuracy: 0.7337\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0671 - accuracy: 0.9880 - val_loss: 1.1669 - val_accuracy: 0.7340\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0558 - accuracy: 0.9916 - val_loss: 1.2536 - val_accuracy: 0.7315\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2536 - accuracy: 0.7315\n"
     ]
    }
   ],
   "source": [
    "# MODELO3. EMBEDDINGS PREENTRENADOS SIN CONGELAR\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(max_words, embedding_dim, input_length=max_comment_length))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.summary()\n",
    "\n",
    "model3.layers[0].set_weights([embedding_matrix])\n",
    "model3.layers[0].trainable = True\n",
    "\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model3.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "score3 = model3.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTV9vvrt1Gz2",
    "outputId": "08463aff-4834-4821-eb04-a46c0bc50253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin word embeddings pre-entrenados\n",
      "Accuracy: 72.98%\n",
      "Con word embeddings pre-entrenados congelados\n",
      "Accuracy: 70.10%\n",
      "Con word embeddings pre-entrenados sin congelar\n",
      "Accuracy: 73.15%\n"
     ]
    }
   ],
   "source": [
    "print(\"Sin word embeddings pre-entrenados\")\n",
    "print(\"Accuracy: %.2f%%\" % (score1[1]*100))\n",
    "print(\"Con word embeddings pre-entrenados congelados\")\n",
    "print(\"Accuracy: %.2f%%\" % (score2[1]*100))\n",
    "print(\"Con word embeddings pre-entrenados sin congelar\")\n",
    "print(\"Accuracy: %.2f%%\" % (score3[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyiM9Iyso1QE"
   },
   "source": [
    "Tras entrenar al clasificador con los tres métodos vemos que el que utiliza embeddings pre-entrenados y los congela da peores resultados que los otros dos. Esto se debe a que la tarea es lo suficientemente específica como para que un pre-entrenamiento más general no sea tan eficiente como el entrenamiento específico. \n",
    "\n",
    "Adicionalmente, el hecho de que el método que no utiliza pre-entrenamiento funcione bien se debe a que la cantidad de muestras que tenemos para el entrenamiento es bastante grande, si fuera muy pequeño este método podría dar muy malos resultados.\n",
    "\n",
    "Sin embargo, el que mejor funciona es el que utiliza pre-entrenamientos pero no los congela. Este método aprovecha tanto la información de los pre-entrenamientos como la de todas las muestras que disponemos y acaba dando un mejor resultado que los otros dos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmM1ftJe3yvK"
   },
   "source": [
    "## 3) Análisis final\n",
    "\n",
    "Analiza con detalle el mejor clasificador. Busca un ejemplo mal clasificado de cada clase, justifica el error ¿se te ocurre alguna forma de solucionarlo?\n",
    "\n",
    "Compara los resultados obtenidos con y sin word embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "qU0UFbSm9NQm",
    "outputId": "611fb719-8b15-49c7-fd19-d0ead899c345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1577 - accuracy: 0.0000e+00\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'petter matteis love time money visually stunning film watch mr mattei offers us vivid portrait human relations movie seems telling us money power success people different situations encounter variation arthur schnitzlers play theme director transfers action present time new york different characters meet connect one connected one way another next person one seems know previous point contact stylishly film sophisticated luxurious look taken see people live world live habitat thing one gets souls picture different stages loneliness one inhabits big city exactly best place human relations find sincere fulfillment one discerns case people encounter acting good mr matteis direction steve buscemi rosario dawson carol kane michael imperioli adrian grenier rest talented cast make characters come alive wish mr mattei good luck await anxiously next work'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(x_test[4:5], y_test[4:5])\n",
    "\n",
    "print(y_test[4])\n",
    "df['review'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNDhSqV4zeX4",
    "outputId": "6e2eee6c-b7a3-48e5-8b84-65e9165e6f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(model1.predict(x_test) >=0.5,dtype= int)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nirvUOCHy2FG",
    "outputId": "223d3364-8687-4e23-8d18-301fa1e61803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "4\n",
      "Resultado que debería dar:  positive\n",
      "Resultado que da nuestro clasificador: negative\n",
      "Imprimimos el mensaje:\n",
      "\n",
      "Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.<br /><br />The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.<br /><br />We wish Mr. Mattei good luck and await anxiously for his next work.\n"
     ]
    }
   ],
   "source": [
    "imbd_file = '/content/drive/MyDrive/IMDB_Dataset.csv'\n",
    "dfo=pd.read_csv(imbd_file)\n",
    "\n",
    "x = 8\n",
    "i = 0\n",
    "while i < len(sentiment_test) and x != 9:\n",
    "  if (0 != np.array(model1.predict(x_test) >=0.5,dtype= int)[i][0] and dfo.sentiment[i]  == 'positive'):\n",
    "    x = 9\n",
    "  else:\n",
    "    i = i +1 \n",
    "print(i)\n",
    "print(\"Resultado que debería dar: \",dfo.sentiment[i])\n",
    "print(\"Resultado que da nuestro clasificador: negative\")\n",
    "print(\"Imprimimos el mensaje:\\n\")\n",
    "print(dfo.review[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afsl2va60n6v"
   },
   "source": [
    "En este ejemplo en el que muestra un resultado negativo cuando debería ser positivo, parece que el clasificador se equivoca debido a unas pocas palabras negativas como \"loneliness\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uL51fKOq2OzI",
    "outputId": "12da8f64-a3b4-48e3-c256-646aab3c0be2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 0s 2ms/step\n",
      "313/313 [==============================] - 0s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "11\n",
      "Resultado que debería dar:  negative\n",
      "Resultado que da nuestro clasificador: positive\n",
      "Imprimimos el mensaje:\n",
      "\n",
      "I saw this movie when I was about 12 when it came out. I recall the scariest scene was the big bird eating men dangling helplessly from parachutes right out of the air. The horror. The horror.<br /><br />As a young kid going to these cheesy B films on Saturday afternoons, I still was tired of the formula for these monster type movies that usually included the hero, a beautiful woman who might be the daughter of a professor and a happy resolution when the monster died in the end. I didn't care much for the romantic angle as a 12 year old and the predictable plots. I love them now for the unintentional humor.<br /><br />But, about a year or so later, I saw Psycho when it came out and I loved that the star, Janet Leigh, was bumped off early in the film. I sat up and took notice at that point. Since screenwriters are making up the story, make it up to be as scary as possible and not from a well-worn formula. There are no rules.\n"
     ]
    }
   ],
   "source": [
    "imbd_file = '/content/drive/MyDrive/IMDB_Dataset.csv'\n",
    "dfo=pd.read_csv(imbd_file)\n",
    "\n",
    "x = 8\n",
    "i = 0\n",
    "while i < len(sentiment_test) and x != 9:\n",
    "  if (0 != np.array(model1.predict(x_test) >=0.5,dtype= int)[i][0] and dfo.sentiment[i]  == 'negative'):\n",
    "    x = 9\n",
    "  else:\n",
    "    i = i +1 \n",
    "print(i)\n",
    "print(\"Resultado que debería dar: \",dfo.sentiment[i])\n",
    "print(\"Resultado que da nuestro clasificador: positive\")\n",
    "print(\"Imprimimos el mensaje:\\n\")\n",
    "print(dfo.review[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1zJ13ml2kXX"
   },
   "source": [
    "En este ejemplo en el que le da una clasificación positiva cuando debería ser negativa es difícil ver la razón, aunque puede que sea porque otras reviews que hablan de ver la película de pequeños son más positivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gT1hLSvuxe7E"
   },
   "source": [
    "Al comparar con los otros métodos sin word embeddings de la primera parte de la práctica, podemos ver que la precisión en test obtenida es muy similar a la que opbteníamos con árboles de decisión. Sin embargo, es peor que la que obteníamos con Naive-Bayes, por lo que este parece ser el mejor método para afrontar esta tarea, y no el de word embeddings."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
